{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from paretoq_qat import replace_linear_with_quantized_linear\n",
    "\n",
    "\n",
    "def quantize_lsq_binary_ternary_extension(\n",
    "    input: Tensor,\n",
    "    alpha: Tensor,\n",
    "    num_bits: int,\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    if num_bits >= 16:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if num_bits == 1 or num_bits == 0:\n",
    "        Qn = -1\n",
    "        Qp = 1\n",
    "    else:\n",
    "        Qn = -(2 ** (num_bits - 1))\n",
    "        Qp = 2 ** (num_bits - 1) - 1\n",
    "\n",
    "    eps = torch.tensor(0.00001, device=alpha.device).float()\n",
    "\n",
    "    alpha = torch.where(alpha > eps, alpha, eps)\n",
    "\n",
    "    if num_bits == 1:\n",
    "        q_w = input.sign()\n",
    "    else:\n",
    "        q_w = (input / alpha).round().clamp(Qn, Qp)\n",
    "\n",
    "    return q_w, alpha\n",
    "\n",
    "\n",
    "def quantize_stretched_elastic_quant(\n",
    "    input: Tensor,\n",
    "    alpha: Tensor,\n",
    "    num_bits: int,\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    if num_bits >= 16:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    eps = torch.tensor(0.00001, device=alpha.device).float()\n",
    "    alpha = torch.where(alpha > eps, alpha, eps)\n",
    "\n",
    "    clip_val = 1 - 1e-2\n",
    "    if num_bits == 0:\n",
    "        n_levels = 1.5\n",
    "        shift = 0\n",
    "    else:\n",
    "        n_levels = 2 ** (num_bits - 1)\n",
    "        shift = 0.5  # type: ignore\n",
    "\n",
    "    if num_bits == 1:\n",
    "        q_w = input.sign()\n",
    "    else:\n",
    "        q_w = (\n",
    "            torch.round(torch.clamp(input / alpha, -clip_val, clip_val) * n_levels - shift) + shift\n",
    "        ) / n_levels\n",
    "\n",
    "    return q_w, alpha\n",
    "\n",
    "\n",
    "def quantize(weight: Tensor, weight_clip_val: Tensor, w_bits: int) -> tuple[Tensor, Tensor]:\n",
    "    if w_bits == 2 or w_bits == 0:\n",
    "        return quantize_stretched_elastic_quant(\n",
    "            weight,\n",
    "            weight_clip_val,\n",
    "            w_bits,\n",
    "        )\n",
    "    elif w_bits <= 4:\n",
    "        return quantize_lsq_binary_ternary_extension(\n",
    "            weight,\n",
    "            weight_clip_val,\n",
    "            w_bits,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4722026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from transformers import AutoModelForCausalLM  # type: ignore\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen3-0.6B\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\",\n",
    ")\n",
    "\n",
    "replace_linear_with_quantized_linear(model, w_bits=4)\n",
    "\n",
    "model_clone = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069fc12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_int4_to_int32(weight: Tensor) -> Tensor:\n",
    "    int4 = weight.int() & 0xF\n",
    "    *rest, last_dim = int4.shape\n",
    "    assert last_dim % 8 == 0, \"Last dim size must be divisible by 8.\"\n",
    "    int4 = int4.view(*rest, last_dim // 8, 8)\n",
    "\n",
    "    packed = torch.zeros(*rest, last_dim // 8, dtype=torch.int32, device=weight.device)\n",
    "    for i in range(8):\n",
    "        packed |= int4[..., i] << (4 * i)\n",
    "\n",
    "    return packed\n",
    "\n",
    "\n",
    "for module in model.modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        if hasattr(module, \"weight_clip_val\"):\n",
    "            quantized_weight, weight_scale = quantize(\n",
    "                module.weight,\n",
    "                module.weight_clip_val,  # type: ignore\n",
    "                w_bits=4,\n",
    "            )\n",
    "            del module.weight\n",
    "            del module.weight_clip_val\n",
    "\n",
    "            module.register_buffer(\"weight_q_packed\", pack_int4_to_int32(quantized_weight))\n",
    "            module.register_buffer(\"weight_scale\", weight_scale)\n",
    "            module.register_buffer(\"weight_bits\", torch.tensor(4, dtype=torch.int8))\n",
    "\n",
    "save_dir = \"Qwen3-0.6B-int4\"\n",
    "model.save_pretrained(save_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa66ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
